{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT-2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmbiguousError/gpt-2-colab/blob/master/GPT_2_345.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoUDfc3rWngR",
        "colab_type": "text"
      },
      "source": [
        "![Constructive](https://imgs.xkcd.com/comics/constructive.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pzxl1vYX-1kk",
        "colab_type": "text"
      },
      "source": [
        "Setup:\n",
        "\n",
        "1) Make sure GPU is enabled, go to edit->notebook settings->Hardware Accelerator GPU\n",
        "\n",
        "2) make a copy to your google drive, click on copy to drive in panel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW0abT07ZkhZ",
        "colab_type": "text"
      },
      "source": [
        "Note: colab will reset after 12 hours make sure to save your model checkpoints to google drive around 10-11 hours mark or before, then go to runtime->reset all runtimes. Now copy your train model back into colab and start training again from the previous checkpoint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLXW02eIYpcB",
        "colab_type": "text"
      },
      "source": [
        "clone and cd into repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIb3hpdKXxfh",
        "colab_type": "text"
      },
      "source": [
        "Look to update scripts from:\n",
        "\n",
        "\n",
        "*   [openai github](https://github.com/openai/gpt-2)\n",
        "*   [nshepperd gitub](https://github.com/nshepperd/gpt-2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICYu3w9hIJkC",
        "colab_type": "code",
        "outputId": "64ba3061-3fed-4f8d-a772-0df5343f5126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#!git clone https://github.com/nshepperd/gpt-2.git\n",
        "!git clone https://github.com/AmbiguousError/gpt-2_FT.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2_FT'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 296 (delta 0), reused 0 (delta 0), pack-reused 293\u001b[K\n",
            "Receiving objects: 100% (296/296), 7.33 MiB | 9.56 MiB/s, done.\n",
            "Resolving deltas: 100% (130/130), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eEIs3ApZUVO",
        "colab_type": "code",
        "outputId": "cd4ef88e-0b38-4dae-9f07-59b8cd203bc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd gpt-2_FT"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt-2_FT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtn1qZPgZLb0",
        "colab_type": "text"
      },
      "source": [
        "install requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "434oOx0bZH6J",
        "colab_type": "code",
        "outputId": "50f2e088-0c45-43f1-bc6a-3e9e22e740d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fire>=0.1.3 (from -r requirements.txt (line 1))\n",
            "  Downloading https://files.pythonhosted.org/packages/5a/b7/205702f348aab198baecd1d8344a90748cb68f53bdcd1cc30cbc08e47d3e/fire-0.1.3.tar.gz\n",
            "Collecting regex==2017.4.5 (from -r requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 25.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n",
            "Collecting tqdm==4.31.1 (from -r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 21.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n",
            "Building wheels for collected packages: fire, regex\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/1a/4d/6b30377c3051e76559d1185c1dbbfff15aed31f87acdd14c22\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
            "Successfully built fire regex\n",
            "\u001b[31mERROR: spacy 2.0.18 has requirement regex==2018.01.10, but you'll have regex 2017.4.5 which is incompatible.\u001b[0m\n",
            "Installing collected packages: fire, regex, tqdm\n",
            "  Found existing installation: regex 2018.1.10\n",
            "    Uninstalling regex-2018.1.10:\n",
            "      Successfully uninstalled regex-2018.1.10\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed fire-0.1.3 regex-2017.4.5 tqdm-4.31.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvUQhgK3PQ4L",
        "colab_type": "text"
      },
      "source": [
        "mount drive to access google drive for saving and accessing checkpoints later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNpf6R4ahYSN",
        "colab_type": "code",
        "outputId": "b4627ed9-bf16-4ce8-984c-b23dc6c532a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1hrgeKFYsuE",
        "colab_type": "text"
      },
      "source": [
        "*download* the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oqeROfICjoN",
        "colab_type": "code",
        "outputId": "a16b9b53-be89-4cc5-89c2-f88a461c5050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lcmz9WN5jPbe",
        "colab_type": "code",
        "outputId": "c4091b77-bc5f-45bf-aa64-0d1f16c88075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gpt-2_FT'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A498TySgHYyF",
        "outputId": "339e0438-8548-4679-b35a-4caf7b6c4019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# !python3 download_model.py 117M\n",
        "# try 345M download\n",
        "!python3 download_model.py 345M"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.00kit [00:00, 807kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 56.9Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 793kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:24, 59.1Mit/s]                                 \n",
            "Fetching model.ckpt.index: 11.0kit [00:00, 7.97Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 927kit [00:00, 46.2Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 50.9Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oJPQtdLbbeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!export PYTHONIOENCODING=UTF-8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KzSbAvePgsI",
        "colab_type": "text"
      },
      "source": [
        "fetch checkpoints if you have them saved in google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA2Wk7yIPmS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp -r /content/drive/My\\ Drive/poetry/ /content/gpt-2/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p--9zwqQRTc",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "lets get our text to train on, in this case from project gutenberg, A Tale of Two Cities, by Charles Dickens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOCvrs-DHvxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget https://www.gutenberg.org/files/98/98-0.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8FCzI_ellzb",
        "colab_type": "text"
      },
      "source": [
        "Join and encode text files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APOxp6uGcuzq",
        "colab_type": "code",
        "outputId": "73595feb-4f95-471a-eb7d-933a2258c15f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#!PYTHONPATH=src ./encode.py /content/drive/My\\ Drive/poetry/ /content/gpt-2_FT/joined.txt.npz\n",
        "\n",
        "# reference 345M model, defaults to 117M\n",
        "!PYTHONPATH=src ./encode.py --model_name='345M' /content/drive/My\\ Drive/poetry/ /content/gpt-2_FT/joined.txt.npz\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading files\n",
            "100% 49/49 [00:33<00:00,  1.54it/s]\n",
            "Writing /content/gpt-2_FT/joined.txt.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPfJ5b3CQXqr",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29F_jttZi_45",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "73a1995e-8609-4777-97f0-b216f1fde027"
      },
      "source": [
        "!pip3 install memory_saving_gradients"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting memory_saving_gradients\n",
            "\u001b[31m  ERROR: Could not find a version that satisfies the requirement memory_saving_gradients (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for memory_saving_gradients\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEn_ihcGI00T",
        "colab_type": "code",
        "outputId": "6e51b092-3038-450b-ddab-53f254abc769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!PYTHONPATH=src ./train.py --dataset /content/gpt-2_FT/joined.txt.npz"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"./train.py\", line 17, in <module>\n",
            "    import memory_saving_gradients\n",
            "ModuleNotFoundError: No module named 'memory_saving_gradients'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS1RJJDFOPnb",
        "colab_type": "text"
      },
      "source": [
        "save our checkpoints to start training again later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JretqG1zOXdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/gpt-2_FT/checkpoint/ /content/drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D-i7vERWbNS",
        "colab_type": "text"
      },
      "source": [
        "use your trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeETvWvrbKga",
        "colab_type": "code",
        "outputId": "423cd168-8936-4576-a941-c6e12a6fccf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!cp -r /content/gpt-2_FT/checkpoint/run1/* /content/gpt-2/models/117M/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: target '/content/gpt-2/models/117M/' is not a directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmnSrXqtfRbq",
        "colab_type": "text"
      },
      "source": [
        "Conditional samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utJj-iY4gHwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8rSqkGxg5OK",
        "colab_type": "text"
      },
      "source": [
        "unconditional samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaQUEnRxWc3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 src/generate_unconditional_samples.py"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}